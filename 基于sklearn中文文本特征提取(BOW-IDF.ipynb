{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>帮我</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>查下</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>明天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>北京</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>天气</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id word\n",
       "0   1   帮我\n",
       "1   1   查下\n",
       "2   1   明天\n",
       "3   1   北京\n",
       "4   1   天气"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('corpus.csv',encoding='gbk')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x10d3a6860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.groupby(['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8] ['帮我', '查下', '明天', '北京', '天气', '怎么样', '帮我', '查下', '今天', '北京', '天气', '好不好', '帮我', '查询', '去', '北京', '的', '火车', '帮我', '查看', '到', '上海', '的', '火车', '帮我', '查看', '特朗普', '的', '新闻', '帮我', '看看', '有没有', '北京', '的', '新闻', '帮我', '搜索', '上海', '有', '什么', '好玩的', '帮我', '找找', '上海', '东方明珠', '在哪']\n"
     ]
    }
   ],
   "source": [
    "id_list=list(df.id)\n",
    "word_list=list(df.word)\n",
    "print(id_list,word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['帮我', '查下', '明天', '北京', '天气', '怎么样']\n",
      "['帮我', '查下', '今天', '北京', '天气', '好不好']\n",
      "['帮我', '查询', '去', '北京', '的', '火车']\n",
      "['帮我', '查看', '到', '上海', '的', '火车']\n",
      "['帮我', '查看', '特朗普', '的', '新闻']\n",
      "['帮我', '看看', '有没有', '北京', '的', '新闻']\n",
      "['帮我', '搜索', '上海', '有', '什么', '好玩的']\n",
      "['帮我', '找找', '上海', '东方明珠', '在哪']\n",
      "['帮我 查下 明天 北京 天气 怎么样', '帮我 查下 今天 北京 天气 好不好', '帮我 查询 去 北京 的 火车', '帮我 查看 到 上海 的 火车', '帮我 查看 特朗普 的 新闻', '帮我 看看 有没有 北京 的 新闻', '帮我 搜索 上海 有 什么 好玩的', '帮我 找找 上海 东方明珠 在哪']\n"
     ]
    }
   ],
   "source": [
    "cps=[]\n",
    "for i in df.groupby(['id']):\n",
    "    \n",
    "    seg_list=list(i[1].word)\n",
    "    \n",
    "    print(seg_list)\n",
    "    seg=' '.join(seg_list)\n",
    "    cps.append(seg)\n",
    "print(cps)\n",
    "    #print(i[1])\n",
    "    #print(i[1].word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>帮我查下明天北京天气怎么样</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>帮我查下今天北京天气好不好</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>帮我查询去北京的火车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>帮我查看到上海的火车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>帮我查看特朗普的新闻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>帮我看看有没有北京的新闻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>帮我搜索上海有什么好玩的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>帮我找找上海东方明珠在哪</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word\n",
       "id               \n",
       "1   帮我查下明天北京天气怎么样\n",
       "2   帮我查下今天北京天气好不好\n",
       "3      帮我查询去北京的火车\n",
       "4      帮我查看到上海的火车\n",
       "5      帮我查看特朗普的新闻\n",
       "6    帮我看看有没有北京的新闻\n",
       "7    帮我搜索上海有什么好玩的\n",
       "8    帮我找找上海东方明珠在哪"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=df.groupby(['id']).sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上海</th>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>东方明珠</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>什么</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今天</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>到</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>北京</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>去</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>在哪</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>天气</th>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好不好</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好玩的</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>帮我</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>怎么样</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>找找</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>搜索</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>新闻</th>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>明天</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有没有</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>查下</th>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>查看</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>查询</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>火车</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>特朗普</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>的</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>看看</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "word          \n",
       "上海    6.333333\n",
       "东方明珠  8.000000\n",
       "什么    7.000000\n",
       "今天    2.000000\n",
       "到     4.000000\n",
       "北京    3.000000\n",
       "去     3.000000\n",
       "在哪    8.000000\n",
       "天气    1.500000\n",
       "好不好   2.000000\n",
       "好玩的   7.000000\n",
       "帮我    4.500000\n",
       "怎么样   1.000000\n",
       "找找    8.000000\n",
       "搜索    7.000000\n",
       "新闻    5.500000\n",
       "明天    1.000000\n",
       "有     7.000000\n",
       "有没有   6.000000\n",
       "查下    1.500000\n",
       "查看    4.500000\n",
       "查询    3.000000\n",
       "火车    3.500000\n",
       "特朗普   5.000000\n",
       "的     4.500000\n",
       "看看    6.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('word').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算词频\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0de7019f69b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'34'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "a_list=[1,'2', '34',5,]\n",
    "b=' '.join(a_list)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'帮我 查下 明天 北京 天气 怎么样'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg=['帮我', '查下', '明天', '北京', '天气', '怎么样']\n",
    "c=' '.join(seg)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'帮我': 1, '查下': 1, '明天': 1, '北京': 1, '天气': 1, '怎么样': 1}\n",
      "{'帮我': 1, '查下': 1, '今天': 1, '北京': 1, '天气': 1, '好不好': 1}\n",
      "{'帮我': 1, '查询': 1, '去': 1, '北京': 1, '的': 1, '火车': 1}\n",
      "{'帮我': 1, '查看': 1, '到': 1, '上海': 1, '的': 1, '火车': 1}\n",
      "{'帮我': 1, '查看': 1, '特朗普': 1, '的': 1, '新闻': 1}\n",
      "{'帮我': 1, '看看': 1, '有没有': 1, '北京': 1, '的': 1, '新闻': 1}\n",
      "{'帮我': 1, '搜索': 1, '上海': 1, '有': 1, '什么': 1, '好玩的': 1}\n",
      "{'帮我': 1, '找找': 1, '上海': 1, '东方明珠': 1, '在哪': 1}\n"
     ]
    }
   ],
   "source": [
    "# 计算词频\n",
    "for i in cps:\n",
    "    ii=i.split(' ')\n",
    "    cfd=dict(nltk.FreqDist(ii))\n",
    "    print(cfd)\n",
    "\n",
    "#d=c.split(' ')\n",
    "#print(dict(nltk.FreqDist(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words\n",
      "['上海', '东方明珠', '什么', '今天', '到', '北京', '去', '在哪', '天气', '好不好', '好玩的', '帮我', '怎么样', '找找', '搜索', '新闻', '明天', '有', '有没有', '查下', '查看', '查询', '火车', '特朗普', '的', '看看']\n",
      "len bag of words: 26\n"
     ]
    }
   ],
   "source": [
    "#用BOW方法计算词袋信息\n",
    "vectoerizer=CountVectorizer(min_df=1,max_df=1.0,token_pattern='\\\\b\\\\w+\\\\b')\n",
    "vectoerizer.fit(cps)\n",
    "bag_of_words=vectorizer.get_feature_names()\n",
    "print('bag of words')\n",
    "print(bag_of_words)\n",
    "print('len bag of words:',len(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoerized copus:\n",
      "[[0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]\n",
      " [1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1]\n",
      " [1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "index of '的' is:24\n"
     ]
    }
   ],
   "source": [
    "X=vectorizer.transform(cps)\n",
    "print(\"Vectoerized copus:\")\n",
    "print(X.toarray())\n",
    "print(\"index of '的' is:{}\".format(vectoerizer.vocabulary_.get('的')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海\t1.8109302162163288\n",
      "东方明珠\t2.504077396776274\n",
      "什么\t2.504077396776274\n",
      "今天\t2.504077396776274\n",
      "到\t2.504077396776274\n",
      "北京\t1.587786664902119\n",
      "去\t2.504077396776274\n",
      "在哪\t2.504077396776274\n",
      "天气\t2.09861228866811\n",
      "好不好\t2.504077396776274\n",
      "好玩的\t2.504077396776274\n",
      "帮我\t1.0\n",
      "怎么样\t2.504077396776274\n",
      "找找\t2.504077396776274\n",
      "搜索\t2.504077396776274\n",
      "新闻\t2.09861228866811\n",
      "明天\t2.504077396776274\n",
      "有\t2.504077396776274\n",
      "有没有\t2.504077396776274\n",
      "查下\t2.09861228866811\n",
      "查看\t2.09861228866811\n",
      "查询\t2.504077396776274\n",
      "火车\t2.09861228866811\n",
      "特朗普\t2.504077396776274\n",
      "的\t1.587786664902119\n",
      "看看\t2.504077396776274\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer()\n",
    "tfidf_transformer.fit(X.toarray())\n",
    "for idx,word in enumerate(vectoerizer.get_feature_names()):\n",
    "    print(\"{}\\t{}\".format(word,tfidf_transformer.idf_[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.3183848\n",
      "  0.         0.         0.42081614 0.         0.         0.20052115\n",
      "  0.50212047 0.         0.         0.         0.50212047 0.\n",
      "  0.         0.42081614 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.50212047 0.         0.3183848\n",
      "  0.         0.         0.42081614 0.50212047 0.         0.20052115\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.42081614 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.33116919\n",
      "  0.52228256 0.         0.         0.         0.         0.20857285\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.52228256 0.43771355 0.\n",
      "  0.33116919 0.        ]\n",
      " [0.38715525 0.         0.         0.         0.53534183 0.\n",
      "  0.         0.         0.         0.         0.         0.21378805\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.44865824 0.         0.44865824 0.\n",
      "  0.33944982 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23187059\n",
      "  0.         0.         0.         0.48660646 0.         0.\n",
      "  0.         0.         0.48660646 0.         0.         0.5806219\n",
      "  0.36816103 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.33116919\n",
      "  0.         0.         0.         0.         0.         0.20857285\n",
      "  0.         0.         0.         0.43771355 0.         0.\n",
      "  0.52228256 0.         0.         0.         0.         0.\n",
      "  0.33116919 0.52228256]\n",
      " [0.33420711 0.         0.4621274  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4621274  0.18454996\n",
      "  0.         0.         0.4621274  0.         0.         0.4621274\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.37686288 0.52110999 0.         0.         0.         0.\n",
      "  0.         0.52110999 0.         0.         0.         0.20810458\n",
      "  0.         0.52110999 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf=tfidf_transformer.transform(X)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
